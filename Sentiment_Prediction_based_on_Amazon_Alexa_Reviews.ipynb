{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89efde5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31b15e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\wecome\\Downloads\\amazon_alexa_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2facbff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>variation</th>\n",
       "      <th>verified_reviews</th>\n",
       "      <th>feedback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>31-Jul-18</td>\n",
       "      <td>Charcoal Fabric</td>\n",
       "      <td>Love my Echo!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>31-Jul-18</td>\n",
       "      <td>Charcoal Fabric</td>\n",
       "      <td>Loved it!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>31-Jul-18</td>\n",
       "      <td>Walnut Finish</td>\n",
       "      <td>Sometimes while playing a game, you can answer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>31-Jul-18</td>\n",
       "      <td>Charcoal Fabric</td>\n",
       "      <td>I have had a lot of fun with this thing. My 4 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>31-Jul-18</td>\n",
       "      <td>Charcoal Fabric</td>\n",
       "      <td>Music</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  rating       date         variation  \\\n",
       "0           0       5  31-Jul-18  Charcoal Fabric    \n",
       "1           1       5  31-Jul-18  Charcoal Fabric    \n",
       "2           2       4  31-Jul-18    Walnut Finish    \n",
       "3           3       5  31-Jul-18  Charcoal Fabric    \n",
       "4           4       5  31-Jul-18  Charcoal Fabric    \n",
       "\n",
       "                                    verified_reviews  feedback  \n",
       "0                                      Love my Echo!         1  \n",
       "1                                          Loved it!         1  \n",
       "2  Sometimes while playing a game, you can answer...         1  \n",
       "3  I have had a lot of fun with this thing. My 4 ...         1  \n",
       "4                                              Music         1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47c4acff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dfe396d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7118b732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3150, 6)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c27c0efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.drop(['Unnamed: 0','rating','date','variation'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f94fc00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verified_reviews</th>\n",
       "      <th>feedback</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Love my Echo!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Loved it!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sometimes while playing a game, you can answer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I have had a lot of fun with this thing. My 4 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Music</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    verified_reviews  feedback\n",
       "0                                      Love my Echo!         1\n",
       "1                                          Loved it!         1\n",
       "2  Sometimes while playing a game, you can answer...         1\n",
       "3  I have had a lot of fun with this thing. My 4 ...         1\n",
       "4                                              Music         1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "779be111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['feedback'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c6fe270",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2893\n",
       "0     257\n",
       "Name: feedback, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['feedback'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc28e50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.loc[df['feedback']=='Extremely Positive','Sentiment'] = 'Positive'\n",
    "df1.loc[df['feedback']=='Extremely Negative','Sentiment'] = 'Negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "749e0b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2893\n",
       "0     257\n",
       "Name: feedback, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['feedback'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abc2f74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd25a88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    no_punct = \"\".join([c for c in text if c not in string.punctuation])\n",
    "    return no_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0eccbdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                         Love my Echo\n",
       "1                                             Loved it\n",
       "2    Sometimes while playing a game you can answer ...\n",
       "3    I have had a lot of fun with this thing My 4 y...\n",
       "4                                                Music\n",
       "Name: verified_reviews, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['verified_reviews'] = df1['verified_reviews'].apply(lambda x: remove_punctuation(x))\n",
    "df1['verified_reviews'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf465c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                     [love, my, echo]\n",
       "1                                          [loved, it]\n",
       "2    [sometimes, while, playing, a, game, you, can,...\n",
       "3    [i, have, had, a, lot, of, fun, with, this, th...\n",
       "4                                              [music]\n",
       "Name: verified_reviews, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "df1['verified_reviews'] = df1['verified_reviews'].apply(lambda x: tokenizer.tokenize(x.lower()))\n",
    "df1['verified_reviews'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fbc8dde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def word_lemmatizer(text):\n",
    "    lem_text = [lemmatizer.lemmatize(i) for i in text]\n",
    "    return lem_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a504cee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                     [love, my, echo]\n",
       "1                                          [loved, it]\n",
       "2    [sometimes, while, playing, a, game, you, can,...\n",
       "3    [i, have, had, a, lot, of, fun, with, this, th...\n",
       "4                                              [music]\n",
       "Name: verified_reviews, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['verified_reviews'] = df1['verified_reviews'].apply(lambda x: word_lemmatizer(x))\n",
    "df1['verified_reviews'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e154920",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\wecome\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\wecome\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"omw-1.4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9d07e8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "\n",
    "def word_stemmer(text):\n",
    "    stem_text = \" \".join([stemmer.stem(i) for i in text])\n",
    "    return stem_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "000d7763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                            love my echo\n",
       "1                                                 love it\n",
       "2       sometim while play a game you can answer a que...\n",
       "3       i have had a lot of fun with thi thing my 4 yr...\n",
       "4                                                   music\n",
       "                              ...                        \n",
       "3145         perfect for kid adult and everyon in between\n",
       "3146    listen to music search locat check time look u...\n",
       "3147    i do love these thing i have them run my entir...\n",
       "3148    onli complaint i have is that the sound qualit...\n",
       "3149                                                 good\n",
       "Name: verified_reviews, Length: 3150, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['verified_reviews'] = df1['verified_reviews'].apply(lambda x: word_stemmer(x))\n",
    "df1['verified_reviews']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8fac3a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df1['verified_reviews']\n",
    "y = df1['feedback']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a11d09a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "75ee4a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(x,y,test_size=0.3,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c450c16c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2205,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "07454df1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2205,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "934ce920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(945,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bdfd2b25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(945,)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f7ca722f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "60c1da2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "889d7fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7d1bc8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pipeline = Pipeline(steps=[('CountVectorizer', CountVectorizer()),\n",
    "                        ('Model', SVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a300b1c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('CountVectorizer', CountVectorizer()), ('Model', SVC())])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_pipeline.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ad657244",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = my_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5706f476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_report               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.07      1.00      0.13         5\n",
      "           1       1.00      0.93      0.96       940\n",
      "\n",
      "    accuracy                           0.93       945\n",
      "   macro avg       0.54      0.97      0.55       945\n",
      "weighted avg       1.00      0.93      0.96       945\n",
      "\n",
      "Confusion Matrix [[  5   0]\n",
      " [ 65 875]]\n",
      "Accuracy_score 0.9312169312169312\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "print(\"classification_report\",classification_report(pred1,y_test))\n",
    "print(\"Confusion Matrix\", confusion_matrix(pred1,y_test))\n",
    "print(\"Accuracy_score\", accuracy_score(pred1,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4a0de75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pipeline2 = Pipeline(steps=[('Countvectorizer', CountVectorizer()),\n",
    "                               ('Model', MultinomialNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fb1bdb17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('Countvectorizer', CountVectorizer()),\n",
       "                ('Model', MultinomialNB())])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_pipeline2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "14c6170e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2 = my_pipeline2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8e778090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_report               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.64      0.34        25\n",
      "           1       0.99      0.94      0.96       920\n",
      "\n",
      "    accuracy                           0.93       945\n",
      "   macro avg       0.61      0.79      0.65       945\n",
      "weighted avg       0.97      0.93      0.95       945\n",
      "\n",
      "Confusion Matrix [[ 16   9]\n",
      " [ 54 866]]\n",
      "Accuracy_score 0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"classification_report\",classification_report(pred2,y_test))\n",
    "print(\"Confusion Matrix\", confusion_matrix(pred2,y_test))\n",
    "print(\"Accuracy_score\", accuracy_score(pred2,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6bb80d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pipeline3 = Pipeline(steps=[('Countvectorizer', CountVectorizer()),\n",
    "                               ('Model', KNeighborsClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bca29b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('CountVectorizer', CountVectorizer()), ('Model', SVC())])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_pipeline.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9f05a06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred3 = my_pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "80bdd881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_report               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.07      1.00      0.13         5\n",
      "           1       1.00      0.93      0.96       940\n",
      "\n",
      "    accuracy                           0.93       945\n",
      "   macro avg       0.54      0.97      0.55       945\n",
      "weighted avg       1.00      0.93      0.96       945\n",
      "\n",
      "Confusion Matrix [[  5   0]\n",
      " [ 65 875]]\n",
      "Accuracy_score 0.9312169312169312\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"classification_report\",classification_report(pred3,y_test))\n",
    "print(\"Confusion Matrix\", confusion_matrix(pred3,y_test))\n",
    "print(\"Accuracy_score\", accuracy_score(pred3,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3c0c5753",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "48bc387f",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pipeline4 = Pipeline(steps=[('CountVectorizer', CountVectorizer()),\n",
    "                               ('Model', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f578d739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('CountVectorizer', CountVectorizer()),\n",
       "                ('Model', LogisticRegression())])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_pipeline4.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b31d2578",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred4 = my_pipeline4.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "02530254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_report               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.74      0.53        39\n",
      "           1       0.99      0.95      0.97       906\n",
      "\n",
      "    accuracy                           0.95       945\n",
      "   macro avg       0.70      0.85      0.75       945\n",
      "weighted avg       0.96      0.95      0.95       945\n",
      "\n",
      "Confusion Matrix [[ 29  10]\n",
      " [ 41 865]]\n",
      "Accuracy_score 0.946031746031746\n"
     ]
    }
   ],
   "source": [
    "print(\"classification_report\",classification_report(pred4,y_test))\n",
    "print(\"Confusion Matrix\", confusion_matrix(pred4,y_test))\n",
    "print(\"Accuracy_score\", accuracy_score(pred4,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a15b6a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a8eb67fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pipeline5 = Pipeline(steps=[('Countvectorizer', CountVectorizer()),\n",
    "                               ('Model', RandomForestClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3dfc075d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('Countvectorizer', CountVectorizer()),\n",
       "                ('Model', RandomForestClassifier())])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_pipeline5.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9314e9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred5 = my_pipeline5.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "33030577",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1fb0ad08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification_report               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.94      0.39        18\n",
      "           1       1.00      0.94      0.97       927\n",
      "\n",
      "    accuracy                           0.94       945\n",
      "   macro avg       0.62      0.94      0.68       945\n",
      "weighted avg       0.98      0.94      0.96       945\n",
      "\n",
      "Confusion Matrix [[ 17   1]\n",
      " [ 53 874]]\n",
      "Accuracy_score 0.9428571428571428\n"
     ]
    }
   ],
   "source": [
    "print(\"classification_report\",classification_report(pred5,y_test))\n",
    "print(\"Confusion Matrix\", confusion_matrix(pred5,y_test))\n",
    "print(\"Accuracy_score\", accuracy_score(pred5,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb19e20",
   "metadata": {},
   "source": [
    "svc: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b182d80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2c882182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Best Model.pkl']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(my_pipeline4,'Best Model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0705c7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = joblib.load(\"Best Model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ae2f6786",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.predict(['Sound is terrible if u want good music too get a bose'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c947cb3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
